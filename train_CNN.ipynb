{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define dataset class\n",
    "class DepthDataset(Dataset):\n",
    "    def __init__(self, image_paths, depth_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.depth_paths = depth_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load RGB image and depth map\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        depth = np.load(self.depth_paths[idx])  # Depth maps are stored as numpy arrays\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return the image and depth map as PyTorch tensors\n",
    "        return torch.tensor(image, dtype=torch.float32).permute(2, 0, 1), \\\n",
    "               torch.tensor(depth, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define CNN model for depth estimation\n",
    "class DepthEstimationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DepthEstimationCNN, self).__init__()\n",
    "        # Encoder: Feature extraction layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        # Decoder: Upsampling layers for depth prediction\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through encoder and decoder\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, dataloader, optimizer, criterion, num_epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for images, depths in dataloader:\n",
    "            images, depths = images.cuda(), depths.cuda()  # Move data to GPU\n",
    "            optimizer.zero_grad()  # Reset gradients\n",
    "            outputs = model(images)  # Forward pass\n",
    "            loss = criterion(outputs, depths)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update model parameters\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Print epoch loss\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(dataloader):.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Define paths for images and depth maps\n",
    "    image_paths = [\"path_to_image_1\", \"path_to_image_2\"]  # Paths to RGB images\n",
    "    depth_paths = [\"path_to_depth_1.npy\", \"path_to_depth_2.npy\"]  # Paths to depth maps\n",
    "\n",
    "    # Create data loader\n",
    "    dataset = DepthDataset(image_paths, depth_paths, transform=None)\n",
    "    dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    model = DepthEstimationCNN().cuda()\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error loss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, dataloader, optimizer, criterion)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
