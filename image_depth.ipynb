{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- [SSD - OpenCV](#sum-of-squared-differencesssd---numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Squared Differences(SSD) - OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "imgL = cv2.imread('./data/tsukuba_l.png',0)\n",
    "imgR = cv2.imread('./data/tsukuba_r.png',0)\n",
    "stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n",
    "disparity = stereo.compute(imgL,imgR)\n",
    "plt.imshow(disparity,'inferno')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Squared Differences(SSD) - Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_disparity(imgL, imgR, num_disparities, block_size):\n",
    "    # Ensure the images are numpy arrays\n",
    "    imgL = np.asarray(imgL, dtype=np.float32)\n",
    "    imgR = np.asarray(imgR, dtype=np.float32)\n",
    "    \n",
    "    # Image dimensions\n",
    "    height, width = imgL.shape\n",
    "    \n",
    "    # Initialize the disparity map\n",
    "    disparity_map = np.zeros((height, width), dtype=np.float32)\n",
    "    \n",
    "    # Half of the block size for easier indexing\n",
    "    half_block = block_size // 2\n",
    "    \n",
    "    # Loop over each pixel in the left image\n",
    "    for y in range(half_block, height - half_block):\n",
    "        for x in range(half_block, width - half_block):\n",
    "            # Define the block region in the left image\n",
    "            blockL = imgL[y - half_block:y + half_block + 1, x - half_block:x + half_block + 1]\n",
    "\n",
    "            # Search range for disparities\n",
    "            min_ssd = float('inf')\n",
    "            best_disparity = 0\n",
    "            for d in range(num_disparities):\n",
    "                if x - d - half_block < 0:\n",
    "                    continue\n",
    "                # Define the block region in the right image\n",
    "                blockR = imgR[y - half_block:y + half_block + 1, x - d - half_block:x - d + half_block + 1]\n",
    "\n",
    "                # Compute the sum of squared differences (SSD)\n",
    "                ssd = np.sum((blockL - blockR) ** 2)\n",
    "\n",
    "                # Update the best disparity if needed\n",
    "                if ssd < min_ssd:\n",
    "                    min_ssd = ssd\n",
    "                    best_disparity = d\n",
    "\n",
    "            # Assign the best disparity to the disparity map\n",
    "            disparity_map[y, x] = best_disparity\n",
    "\n",
    "    return disparity_map\n",
    "\n",
    "# Load grayscale images as numpy arrays\n",
    "imgL = plt.imread('./data/tsukuba_l.png')\n",
    "imgR = plt.imread('./data/tsukuba_r.png')\n",
    "\n",
    "# Ensure the images are 2D arrays (grayscale)\n",
    "if imgL.ndim == 3:\n",
    "    imgL = imgL[:, :, 0]  # Convert to grayscale if needed\n",
    "if imgR.ndim == 3:\n",
    "    imgR = imgR[:, :, 0]  # Convert to grayscale if needed\n",
    "\n",
    "# Parameters\n",
    "num_disparities = 16\n",
    "block_size = 20\n",
    "\n",
    "# Compute disparity\n",
    "disparity = compute_disparity(imgL, imgR, num_disparities, block_size)\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(imgL)\n",
    "plt.title('Original Image')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Display the disparity map\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(disparity, cmap='inferno')\n",
    "plt.colorbar()\n",
    "plt.title('Disparity Map')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_disparity_optimized(imgL, imgR, num_disparities, block_size):\n",
    "    # Get image dimensions and set half the block size for easier indexing\n",
    "    height, width = imgL.shape\n",
    "    half_block = block_size // 2\n",
    "    \n",
    "    # Initialize the disparity map\n",
    "    disparity_map = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "    # Loop through each pixel in the left image (y and x)\n",
    "    for y in prange(half_block, height - half_block):\n",
    "        for x in range(half_block, width - half_block):\n",
    "            # Extract the block from the left image\n",
    "            blockL = imgL[y - half_block:y + half_block + 1, x - half_block:x + half_block + 1]\n",
    "            \n",
    "            # Initialize SSD (Sum of Squared Differences) and best disparity\n",
    "            min_ssd = float('inf')\n",
    "            best_disparity = 0\n",
    "            \n",
    "            # Loop through all disparity values (d)\n",
    "            for d in range(num_disparities):\n",
    "                if x - d - half_block < 0:\n",
    "                    break  # Skip if the right image goes out of bounds\n",
    "                \n",
    "                # Extract the block from the right image\n",
    "                blockR = imgR[y - half_block:y + half_block + 1, x - d - half_block:x - d + half_block + 1]\n",
    "                \n",
    "                # Compute the SSD between the left and right blocks\n",
    "                ssd = np.sum((blockL - blockR) ** 2)\n",
    "                \n",
    "                # Update the best disparity if a smaller SSD is found\n",
    "                if ssd < min_ssd:\n",
    "                    min_ssd = ssd\n",
    "                    best_disparity = d\n",
    "            \n",
    "            # Assign the best disparity for the current pixel\n",
    "            disparity_map[y, x] = best_disparity\n",
    "    \n",
    "    return disparity_map\n",
    "\n",
    "# Load and process images\n",
    "imgL = plt.imread('./data/tsukuba_l.png')\n",
    "imgR = plt.imread('./data/tsukuba_r.png')\n",
    "\n",
    "# Convert to grayscale if the images have 3 channels\n",
    "if imgL.ndim == 3:\n",
    "    imgL = imgL[:, :, 0]  # Convert to grayscale if needed\n",
    "if imgR.ndim == 3:\n",
    "    imgR = imgR[:, :, 0]\n",
    "\n",
    "# Normalize images (optional, to improve numerical stability)\n",
    "imgL = (imgL - imgL.min()) / (imgL.max() - imgL.min())\n",
    "imgR = (imgR - imgR.min()) / (imgR.max() - imgR.min())\n",
    "\n",
    "# Set parameters\n",
    "num_disparities = 16\n",
    "block_size = 9\n",
    "\n",
    "# Compute the disparity map using the optimized function\n",
    "disparity = compute_disparity_optimized(imgL, imgR, num_disparities, block_size)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(imgL, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(disparity, cmap='inferno')\n",
    "plt.colorbar()\n",
    "plt.title('Disparity Map (Optimized)')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Read the images (left and right images)\n",
    "imgL = cv2.imread('./data/tsukuba_l.png', 0)  # Left image (grayscale)\n",
    "imgR = cv2.imread('./data/tsukuba_r.png', 0)  # Right image (grayscale)\n",
    "\n",
    "# Create ORB feature detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors for both images\n",
    "kpL, desL = orb.detectAndCompute(imgL, None)  # Keypoints and descriptors for left image\n",
    "kpR, desR = orb.detectAndCompute(imgR, None)  # Keypoints and descriptors for right image\n",
    "\n",
    "# Create a brute-force matcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Match descriptors between the left and right images\n",
    "matches = bf.match(desL, desR)\n",
    "\n",
    "# Visualize the matched keypoints\n",
    "img_matches = cv2.drawMatches(imgL, kpL, imgR, kpR, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# Display the matched keypoints\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(img_matches)\n",
    "plt.title('Feature Matches')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MiDaS model\n",
    "model_type = \"DPT_Large\"  # Options: \"DPT_Large\", \"DPT_Hybrid\", \"MiDaS_small\"\n",
    "midas = torch.hub.load(\"intel-isl/MiDaS\", model_type)\n",
    "\n",
    "# Move model to appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "# Load MiDaS transform\n",
    "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
    "transform = midas_transforms.dpt_transform if model_type in [\"DPT_Large\", \"DPT_Hybrid\"] else midas_transforms.small_transform\n",
    "\n",
    "# Load and preprocess the input image\n",
    "input_image = cv2.imread(\"./train_data/origin/image_83.jpg\")  # Replace with your image path\n",
    "input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "input_batch = transform(input_image).to(device)\n",
    "\n",
    "# Perform depth estimation\n",
    "with torch.no_grad():\n",
    "    prediction = midas(input_batch)\n",
    "    prediction = torch.nn.functional.interpolate(\n",
    "        prediction.unsqueeze(1),\n",
    "        size=input_image.shape[:2],\n",
    "        mode=\"bicubic\",\n",
    "        align_corners=False,\n",
    "    ).squeeze()\n",
    "\n",
    "# Normalize the depth map for visualization\n",
    "depth_map = prediction.cpu().numpy()\n",
    "depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Input Image\")\n",
    "plt.imshow(input_image)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Depth Map\")\n",
    "plt.imshow(depth_map, cmap=\"inferno\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # Visualization library\n",
    "\n",
    "# Input image generation (example uses a random grayscale image)\n",
    "image_height, image_width = 100, 100  # Image dimensions\n",
    "\n",
    "# 1. Convert to Grayscale\n",
    "# Grayscale formula: 0.2989*R + 0.5870*G + 0.1140*B\n",
    "gray_image = cv2.imread('./data/test.png', 0)  # Load image in grayscale mode\n",
    "\n",
    "# 2. Simple depth estimation (Edge-based Depth)\n",
    "# Edge detection using Sobel filter (vertical and horizontal directions)\n",
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])  # X-direction filter\n",
    "sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])  # Y-direction filter\n",
    "\n",
    "# Perform convolution to calculate gradient magnitudes\n",
    "depth_x = np.zeros_like(gray_image)  # Initialize gradient in X direction\n",
    "depth_y = np.zeros_like(gray_image)  # Initialize gradient in Y direction\n",
    "\n",
    "# Apply Sobel filters to calculate gradients\n",
    "for i in range(1, gray_image.shape[0] - 1):\n",
    "    for j in range(1, gray_image.shape[1] - 1):\n",
    "        region = gray_image[i-1:i+2, j-1:j+2]  # Extract 3x3 region\n",
    "        depth_x[i, j] = np.sum(region * sobel_x)  # Convolve with Sobel X\n",
    "        depth_y[i, j] = np.sum(region * sobel_y)  # Convolve with Sobel Y\n",
    "\n",
    "# 3. Compute the final depth map\n",
    "# Combine horizontal and vertical gradients to compute magnitude\n",
    "depth_map = np.sqrt(depth_x**2 + depth_y**2)\n",
    "\n",
    "# 4. Normalize the depth map to range 0-1\n",
    "depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Display the input grayscale image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Input Image\")\n",
    "plt.imshow(gray_image, cmap=\"inferno\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Display the computed depth map\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Depth Map\")\n",
    "plt.imshow(depth_map, cmap=\"inferno\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Load input image (example image used)\n",
    "image_height, image_width = 100, 100\n",
    "\n",
    "# 1. Convert to Grayscale\n",
    "gray_image = cv2.imread('test.png', 0)  # Load image in grayscale mode\n",
    "\n",
    "# 2. Multi-Scale Feature Extraction\n",
    "def downsample(image, scale):\n",
    "    \"\"\"Reduce the size of an image by the given scale factor\"\"\"\n",
    "    h, w = image.shape\n",
    "    new_h, new_w = h // scale, w // scale\n",
    "    return image[::scale, ::scale]\n",
    "\n",
    "def upsample(image, original_shape):\n",
    "    \"\"\"Enlarge an image to match the original shape\"\"\"\n",
    "    scale_h = original_shape[0] // image.shape[0]\n",
    "    scale_w = original_shape[1] // image.shape[1]\n",
    "    return np.repeat(np.repeat(image, scale_h, axis=0), scale_w, axis=1)\n",
    "\n",
    "# Define scales for multi-scale features\n",
    "scales = [1, 2, 4]\n",
    "multi_scale_features = [gray_image] + [downsample(gray_image, scale) for scale in scales]\n",
    "\n",
    "# Initialize combined feature map with float64 type\n",
    "combined_feature = np.zeros_like(gray_image, dtype=np.float64)\n",
    "\n",
    "# Combine multi-scale features\n",
    "for feature in multi_scale_features:\n",
    "    if feature.shape != gray_image.shape:\n",
    "        # Upsample smaller-scale images to match original image size\n",
    "        feature = upsample(feature, gray_image.shape)\n",
    "        # Debug visualization for each feature\n",
    "        plt.imshow(feature, cmap=\"inferno\")\n",
    "        plt.show()\n",
    "    combined_feature += feature\n",
    "\n",
    "# Normalize the combined feature map after float operations\n",
    "combined_feature /= len(multi_scale_features)\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Display the input grayscale image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Input Image\")\n",
    "plt.imshow(gray_image, cmap=\"inferno\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Display the combined feature map\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Combined Feature\")\n",
    "plt.imshow(combined_feature, cmap=\"inferno\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 4. Sobel Edge Detection (Simple depth cue)\n",
    "sobel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])  # X-direction filter\n",
    "sobel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])  # Y-direction filter\n",
    "\n",
    "# Initialize gradient maps for X and Y directions\n",
    "depth_x = np.zeros_like(combined_feature)\n",
    "depth_y = np.zeros_like(combined_feature)\n",
    "\n",
    "# Apply Sobel filters to calculate gradients\n",
    "for i in range(1, combined_feature.shape[0] - 1):\n",
    "    for j in range(1, combined_feature.shape[1] - 1):\n",
    "        region = combined_feature[i-1:i+2, j-1:j+2]  # Extract 3x3 region\n",
    "        depth_x[i, j] = np.sum(region * sobel_x)  # Convolve with Sobel X\n",
    "        depth_y[i, j] = np.sum(region * sobel_y)  # Convolve with Sobel Y\n",
    "\n",
    "# Compute final depth map as the magnitude of gradients\n",
    "depth_map = np.sqrt(depth_x**2 + depth_y**2)\n",
    "\n",
    "# 5. Normalize depth map to range 0-1\n",
    "depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min())\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Display the input grayscale image\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Input Image\")\n",
    "plt.imshow(gray_image, cmap=\"inferno\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# Display the edge-detected depth map\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Edge Detection\")\n",
    "plt.imshow(depth_map, cmap=\"inferno\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
